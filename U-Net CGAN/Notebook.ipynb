{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from enum import Enum\n",
    "import os\n",
    "\n",
    "class Execution(Enum):\n",
    "    Local = \"Local\"\n",
    "    Colab = \"Colab\"\n",
    "\n",
    "if \"F:\" in os.getcwd():\n",
    "    execution = Execution.Local\n",
    "else:\n",
    "    execution = Execution.Colab\n",
    "\n",
    "if execution == Execution.Colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "\n",
    "!pip install wandb -qU\n",
    "import wandb\n",
    "wandb.login()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qdLQYTne6wTW",
    "outputId": "28a40cc0-7a20-4f41-e3e7-288ef41efd6c"
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#Hyperparams"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:klzmcldx) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparams= {\n",
    "            \"epochs\": 100,\n",
    "            \"batch_size\": 128,\n",
    "            \"image_size\": 64,\n",
    "            \"latent_dim\": 100,\n",
    "            \"dataset_labels\": 7,\n",
    "            \"clip_value\": 0.01,\n",
    "            \"lr\": 0.001,\n",
    "            \"dropout\": 0.5,\n",
    "            \"beta_1\": 0.9,\n",
    "            \"beta_2\": 0.99,\n",
    "            \"n_critic\": 5,\n",
    "            \"grad_weight\": 10,\n",
    "            \"execution\": execution\n",
    "            }\n",
    "\n",
    "wandb.init(\n",
    "    project=\"WCGAN\",\n",
    "    config=hyperparams)\n",
    "\n",
    "# Copy your config\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Custom layers"
   ],
   "metadata": {
    "id": "rVKBBs5S66ZX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.layers import Layer, InputSpec\n",
    "\n",
    "try:\n",
    "    from keras import initializations\n",
    "except ImportError:\n",
    "    from keras import initializers as initializations\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "class Scale(Layer):\n",
    "    '''Custom Layer for DenseNet used for BatchNormalization.\n",
    "\n",
    "    Learns a set of weights and biases used for scaling the input data.\n",
    "    the output consists simply in an element-wise multiplication of the input\n",
    "    and a sum of a set of constants:\n",
    "\n",
    "        out = in * gamma + beta,\n",
    "\n",
    "    where 'gamma' and 'beta' are the weights and biases larned.\n",
    "\n",
    "    # Arguments\n",
    "        axis: integer, axis along which to normalize in mode 0. For instance,\n",
    "            if your input tensor has shape (samples, channels, rows, cols),\n",
    "            set axis to 1 to normalize per feature map (channels axis).\n",
    "        momentum: momentum in the computation of the\n",
    "            exponential average of the mean and standard deviation\n",
    "            of the data, for feature-wise normalization.\n",
    "        weights: Initialization weights.\n",
    "            List of 2 Numpy arrays, with shapes:\n",
    "            `[(input_shape,), (input_shape,)]`\n",
    "        beta_init: name of initialization function for shift parameter\n",
    "            (see [initializations](../initializations.md)), or alternatively,\n",
    "            Theano/TensorFlow function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "        gamma_init: name of initialization function for scale parameter (see\n",
    "            [initializations](../initializations.md)), or alternatively,\n",
    "            Theano/TensorFlow function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, weights=None, axis=-1, momentum=0.9, beta_init='zero', gamma_init='one', **kwargs):\n",
    "        self.momentum = momentum\n",
    "        self.axis = axis\n",
    "        self.beta_init = initializations.get(beta_init)\n",
    "        self.gamma_init = initializations.get(gamma_init)\n",
    "        self.initial_weights = weights\n",
    "        super(Scale, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        shape = (int(input_shape[self.axis]),)\n",
    "\n",
    "        # Tensorflow >= 1.0.0 compatibility\n",
    "        self.gamma = K.variable(self.gamma_init(shape), name='{}_gamma'.format(self.name))\n",
    "        self.beta = K.variable(self.beta_init(shape), name='{}_beta'.format(self.name))\n",
    "        # self.gamma = self.gamma_init(shape, name='{}_gamma'.format(self.name))\n",
    "        # self.beta = self.beta_init(shape, name='{}_beta'.format(self.name))\n",
    "        self._trainable_weights = [self.gamma, self.beta]\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"momentum\": self.momentum, \"axis\": self.axis}\n",
    "        base_config = super(Scale, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "-GbeGkri5mOl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#DenseNet"
   ],
   "metadata": {
    "id": "FcHRzhrc7FnR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import LayerNormalization\n",
    "from keras.layers import ZeroPadding2D, Concatenate\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "def DenseNet(img_input_layer, img_n_label_input_layer, label_input_layer, nb_dense_block=4, growth_rate=32, nb_filter=64, reduction=0.0, dropout_rate=0.0, weight_decay=1e-4,\n",
    "             classes=1000, weights_path=None):\n",
    "    \"\"\"Instantiate the DenseNet 121 architecture,\n",
    "        # Arguments\n",
    "            nb_dense_block: number of dense blocks to add to end\n",
    "            growth_rate: number of filters to add per dense block\n",
    "            nb_filter: initial number of filters\n",
    "            reduction: reduction factor of transition blocks.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "            classes: optional number of classes to classify images\n",
    "            weights_path: path to pre-trained weights\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "    \"\"\"\n",
    "    eps = 1.1e-5\n",
    "\n",
    "    # compute compression factor\n",
    "    compression = 1.0 - reduction\n",
    "\n",
    "    # Handle Dimension Ordering for different backends\n",
    "    global concat_axis\n",
    "    if K.image_data_format() == 'channels_last': # Tensorflow\n",
    "        concat_axis = 3\n",
    "        # img_input = Input(shape=(224, 224, 3), name='data')\n",
    "        img_input = img_n_label_input_layer\n",
    "    else: # Theano\n",
    "        concat_axis = 1\n",
    "        # img_input = Input(shape=(3, 224, 224), name='data')\n",
    "        img_input = img_n_label_input_layer\n",
    "\n",
    "    # From architecture for ImageNet (Table 1 in the paper)\n",
    "    nb_filter = 64\n",
    "    nb_layers = [6, 12, 24, 16]  # For DenseNet-121\n",
    "\n",
    "    # Initial convolution\n",
    "    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)\n",
    "    x = Convolution2D(nb_filter, (7, 7), strides=(2, 2), name='conv1', use_bias=False)(x)\n",
    "    x = LayerNormalization(epsilon=eps, axis=concat_axis, name='conv1_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name='conv1_scale')(x)\n",
    "    x = Activation('relu', name='relu1')(x)\n",
    "    x = ZeroPadding2D((1, 1), name='pool1_zeropadding')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    # Add dense blocks\n",
    "    for block_idx in range(nb_dense_block - 1):\n",
    "        stage = block_idx + 2\n",
    "        x, nb_filter = dense_block(x, stage, nb_layers[block_idx], nb_filter, growth_rate, dropout_rate=dropout_rate,\n",
    "                                   weight_decay=weight_decay)\n",
    "\n",
    "        # Add transition_block\n",
    "        x = transition_block(x, stage, nb_filter, compression=compression, dropout_rate=dropout_rate,\n",
    "                             weight_decay=weight_decay)\n",
    "        nb_filter = int(nb_filter * compression)\n",
    "\n",
    "    final_stage = stage + 1\n",
    "    x, nb_filter = dense_block(x, final_stage, nb_layers[-1], nb_filter, growth_rate, dropout_rate=dropout_rate,\n",
    "                               weight_decay=weight_decay)\n",
    "\n",
    "    x = LayerNormalization(epsilon=eps, axis=concat_axis, name='conv' + str(final_stage) + '_blk_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name='conv' + str(final_stage) + '_blk_scale')(x)\n",
    "    x = Activation('relu', name='relu' + str(final_stage) + '_blk')(x)\n",
    "    x = GlobalAveragePooling2D(name='pool' + str(final_stage))(x)\n",
    "\n",
    "    x = Dense(classes, name='fc6')(x)\n",
    "    x = Activation('sigmoid', name='prob')(x)\n",
    "\n",
    "    model = Model(inputs=[img_input_layer, label_input_layer], outputs=x, name='densenet')\n",
    "\n",
    "    if weights_path is not None:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def conv_block(x, stage, branch, nb_filter, dropout_rate=None, weight_decay=1e-4):\n",
    "    '''Apply BatchNorm, Relu, bottleneck 1x1 Conv2D, 3x3 Conv2D, and option dropout\n",
    "        # Arguments\n",
    "            x: input tensor\n",
    "            stage: index for dense block\n",
    "            branch: layer index within each dense block\n",
    "            nb_filter: number of filters\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    conv_name_base = 'conv' + str(stage) + '_' + str(branch)\n",
    "    relu_name_base = 'relu' + str(stage) + '_' + str(branch)\n",
    "\n",
    "    # 1x1 Convolution (Bottleneck layer)\n",
    "    inter_channel = nb_filter * 4\n",
    "    x = LayerNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base + '_x1_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base + '_x1_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base + '_x1')(x)\n",
    "    x = Convolution2D(inter_channel, (1, 1), name=conv_name_base + '_x1', use_bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 3x3 Convolution\n",
    "    x = LayerNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base + '_x2_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base + '_x2_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base + '_x2')(x)\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base + '_x2_zeropadding')(x)\n",
    "    x = Convolution2D(nb_filter, (3, 3), name=conv_name_base + '_x2', use_bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, stage, nb_filter, compression=1.0, dropout_rate=None, weight_decay=1E-4):\n",
    "    ''' Apply BatchNorm, 1x1 Convolution, averagePooling, optional compression, dropout\n",
    "        # Arguments\n",
    "            x: input tensor\n",
    "            stage: index for dense block\n",
    "            nb_filter: number of filters\n",
    "            compression: calculated as 1 - reduction. Reduces the number of feature maps in the transition block.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "    '''\n",
    "\n",
    "    eps = 1.1e-5\n",
    "    conv_name_base = 'conv' + str(stage) + '_blk'\n",
    "    relu_name_base = 'relu' + str(stage) + '_blk'\n",
    "    pool_name_base = 'pool' + str(stage)\n",
    "\n",
    "    x = LayerNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base + '_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base + '_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base)(x)\n",
    "    x = Convolution2D(int(nb_filter * compression), (1, 1), name=conv_name_base, use_bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2), name=pool_name_base)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def dense_block(x, stage, nb_layers, nb_filter, growth_rate, dropout_rate=None, weight_decay=1e-4,\n",
    "                grow_nb_filters=True):\n",
    "    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones\n",
    "        # Arguments\n",
    "            x: input tensor\n",
    "            stage: index for dense block\n",
    "            nb_layers: the number of layers of conv_block to append to the model.\n",
    "            nb_filter: number of filters\n",
    "            growth_rate: growth rate\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "            grow_nb_filters: flag to decide to allow number of filters to grow\n",
    "    '''\n",
    "\n",
    "    eps = 1.1e-5\n",
    "    concat_feat = x\n",
    "\n",
    "    for i in range(nb_layers):\n",
    "        branch = i + 1\n",
    "        x = conv_block(concat_feat, stage, branch, growth_rate, dropout_rate, weight_decay)\n",
    "        concat_feat = Concatenate()([concat_feat, x])\n",
    "\n",
    "        if grow_nb_filters:\n",
    "            nb_filter += growth_rate\n",
    "\n",
    "    return concat_feat, nb_filter"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "StdVnd1h5mOs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "aNCTXhAT5mOu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from numpy import expand_dims\n",
    "from numpy.random import randint\n",
    "from numpy.random import randn\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Define datagen. Here we can define any transformations we want to apply to images\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "# define training directory that contains subfolders\n",
    "if execution == Execution.Colab:\n",
    "    train_dir = os.path.join(\"gdrive\", \"My Drive\", \"Datasets\", \"HAM10000\", \"reorganized\")\n",
    "    save_dir_root = os.path.join(\"gdrive\", \"My Drive\", \"models\")\n",
    "elif execution == Execution.Local:\n",
    "    train_dir = os.path.join(\"F:\", os.sep, \"backup\", \"Facultad\", \"Tesis\", \"DL\", \"datasets\", \"HAM10000\", \"data\", \"reorganized\")\n",
    "    save_dir_root = os.path.join(\"F:\", os.sep, \"backup\", \"Facultad\", \"Tesis\", \"DL\", \"U-Net CGAN\", \"models\")\n",
    "\n",
    "def create_save_dir():\n",
    "    run_date = datetime.today().strftime('%Y-%m-%d %H-%M')\n",
    "    save_dir_name = os.path.join(save_dir_root, run_date)\n",
    "    #check if dir already exists\n",
    "    if not os.path.isdir(save_dir_name):\n",
    "        # prepare dir\n",
    "        os.mkdir(save_dir_name, 0o666)\n",
    "    return save_dir_name\n",
    "\n",
    "\n",
    "def save_models(epoch, g_model, d_model, dir_name):\n",
    "    filename = 'dis_model_%03d.h5' % (epoch + 1)\n",
    "    d_model.save(os.path.join(dir_name, filename))\n",
    "    print(\"Discriminator model saved\")\n",
    "    filename = 'gen_model_%03d.h5' % (epoch + 1)\n",
    "    g_model.save(os.path.join(dir_name, filename))\n",
    "    print(\"Generator model saved\")\n",
    "    \n",
    "def save_hyperparams(dir_name):    \n",
    "    with open(os.path.join(dir_name, \"hyperparams.txt\"), 'w') as f:\n",
    "        print(hyperparams, file=f)\n",
    "    print(\"Hyperparams saved\")\n",
    "\n",
    "def load_real_data_old():\n",
    "    # load dataset\n",
    "    (trainX, trainy), (_, _) = load_data()\n",
    "    # expand to 3d, e.g. add channels\n",
    "    X = expand_dims(trainX, axis=-1)\n",
    "    # convert from ints to floats\n",
    "    X = X.astype('float32')\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return [X, trainy]\n",
    "\n",
    "\n",
    "def load_real_data():\n",
    "    # emulation dataset loading\n",
    "    train_data_keras = datagen.flow_from_directory(directory=train_dir,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   batch_size=1,  # 16 images at a time\n",
    "                                                   target_size=(config.image_size, config.image_size),\n",
    "                                                   color_mode='grayscale')  # Resize images\n",
    "    # split into images and labels\n",
    "    images, labels = next(train_data_keras)\n",
    "    size = train_data_keras.samples\n",
    "    images = numpy.zeros([size, images[0][0].size, images[0][0].size, 1])\n",
    "    return [images, labels]\n",
    "\n",
    "\n",
    "def get_images_and_labels(n_samples):\n",
    "    train_data_keras = datagen.flow_from_directory(directory=train_dir,\n",
    "                                                   class_mode='sparse',\n",
    "                                                   batch_size=n_samples,  # 16 images at a time\n",
    "                                                   target_size=(config.image_size, config.image_size),\n",
    "                                                   color_mode='grayscale')  # Resize images\n",
    "    # split into images and labels\n",
    "    images, labels = next(train_data_keras)\n",
    "    # labels = numpy.argmax(labels, axis=-1)\n",
    "    # convert from ints to floats\n",
    "    images = images.astype('float32')\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    images = (images - 127.5) / 127.5\n",
    "    # generate class labels\n",
    "    return images, labels.astype(int)\n",
    "\n",
    "\n",
    "def generate_real_samples(n_samples):\n",
    "    images, labels = get_images_and_labels(n_samples)\n",
    "    # generate class labels\n",
    "    y = -ones((n_samples, 1))\n",
    "    return images, labels, y\n",
    "\n",
    "\n",
    "def get_noise(latent_dim, n_samples):\n",
    "    return randn(latent_dim * n_samples).reshape(n_samples, latent_dim)\n",
    "\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    img_input, labels_input = get_images_and_labels(n_samples)\n",
    "    z_input = get_noise(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    images = generator([img_input, labels_input, z_input])\n",
    "    # create class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return images, labels_input, y\n",
    "\n",
    "\n",
    "def save_plot(examples, epoch, n=10):\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        pyplot.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
    "    # save plot to file\n",
    "    filename = 'generated_plot_e%03d.png' % (epoch + 1)\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()\n",
    "\n",
    "\n",
    "def gradient_penalty(discriminator, batch_size, real_images, fake_images, labels):\n",
    "        \"\"\"Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = discriminator([interpolated, labels])\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "\n",
    "from enum import IntEnum\n",
    "\n",
    "\n",
    "class FashionLabel(IntEnum):\n",
    "    Tshirt = 0\n",
    "    Trouser = 1\n",
    "    Pullover = 2\n",
    "    Dress = 3\n",
    "    Coat = 4\n",
    "    Sandal = 5\n",
    "    Shirt = 6\n",
    "    Sneaker = 7\n",
    "    Bag = 8\n",
    "    Ankle_boot = 9\n",
    "\n",
    "class CancerLabel(IntEnum):\n",
    "    akiec = 0\n",
    "    bcc = 1\n",
    "    bkl = 2\n",
    "    df = 3\n",
    "    mel = 4\n",
    "    nv = 5\n",
    "    vasc = 6"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "b6JcpiTw5mOx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Nets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "zu9LYlNZ5mOy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend\n",
    "from keras.constraints import Constraint\n",
    "from keras.layers import Input, Dense, Concatenate, ReLU, Conv2D, Conv2DTranspose, Reshape, LayerNormalization, \\\n",
    "    Activation, Embedding, LeakyReLU, Dropout\n",
    "from keras.models import Model\n",
    "from tensorflow import Tensor, keras\n",
    "\n",
    "\n",
    "w_initializer = tf.keras.initializers.TruncatedNormal(mean=0., stddev=0.02)\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "# clip model weights to a given hypercube\n",
    "class ClipConstraint(Constraint):\n",
    "    # set clip value when initialized\n",
    "    def __init__(self, clip_value):\n",
    "        self.clip_value = clip_value\n",
    "\n",
    "    # clip model weights to hypercube\n",
    "    def __call__(self, weights):\n",
    "        return backend.clip(weights, -self.clip_value, self.clip_value)\n",
    "\n",
    "    # get the config\n",
    "    def get_config(self):\n",
    "        return {'clip_value': self.clip_value}\n",
    "\n",
    "\n",
    "def up_scaling_layer(x, n_filters):\n",
    "    kernel = 1\n",
    "    stride = 2\n",
    "    x = Conv2DTranspose(n_filters, kernel_size=kernel, strides=stride, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(config.dropout)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def down_scaling_layer(x, n_filters):\n",
    "    kernel = 1\n",
    "    stride = 2\n",
    "    x = Conv2D(n_filters, kernel_size=kernel, strides=stride, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(config.dropout)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resNet_block(x, n_filters, scaling):\n",
    "    kernel = 3\n",
    "    stride = 1\n",
    "    x = Conv2D(n_filters, kernel_size=kernel, strides=stride, padding='same')(x)\n",
    "    x = Conv2D(n_filters, kernel_size=kernel, strides=stride, padding='same')(x)\n",
    "    x = Conv2D(n_filters, kernel_size=kernel, strides=stride, padding='same')(x)\n",
    "    x = Conv2D(n_filters, kernel_size=kernel, strides=stride, padding='same')(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    if scaling == 'up':\n",
    "        x = up_scaling_layer(x, n_filters)\n",
    "    else:\n",
    "        x = down_scaling_layer(x, n_filters)\n",
    "    return x\n",
    "\n",
    "\n",
    "def representation_layer(layer, noise_input):\n",
    "    filter = 3\n",
    "    stride = 2\n",
    "    kernel = 4\n",
    "\n",
    "    noise_block_size = int(layer.shape[1]/2)\n",
    "\n",
    "    dense = Dense(noise_block_size * noise_block_size * filter, kernel_initializer=w_initializer)(noise_input)\n",
    "\n",
    "    reshape = Reshape((noise_block_size, noise_block_size, filter))(dense)\n",
    "\n",
    "    noise_conv = Conv2DTranspose(kernel_size=kernel,\n",
    "                                 strides=stride,\n",
    "                                 filters=2 * filter,\n",
    "                                 padding=\"same\",\n",
    "                                 kernel_initializer=w_initializer)(reshape)\n",
    "    concat_layer = Concatenate()([layer, noise_conv])\n",
    "    return concat_layer\n",
    "\n",
    "\n",
    "def img_n_label_layer(input_shape, n_classes):\n",
    "    # label input\n",
    "    label_input_layer = Input(shape=(1,))\n",
    "    # embedding for categorical input\n",
    "    li = Embedding(n_classes, 50)(label_input_layer)\n",
    "    # scale up to image dimensions with linear activation\n",
    "    n_nodes = input_shape[0] * input_shape[1]\n",
    "    li = Dense(n_nodes)(li)\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((input_shape[0], input_shape[1], 1))(li)\n",
    "    # image input\n",
    "    img_input_layer = Input(shape=input_shape)\n",
    "    # concat label as a channel\n",
    "    img_n_label_input_layer = Concatenate()([img_input_layer, li])\n",
    "    return img_input_layer, img_n_label_input_layer, label_input_layer\n",
    "\n",
    "\n",
    "def define_generator(latent_dim, input_shape, n_classes):\n",
    "    n_filters = 3\n",
    "\n",
    "    img_input_layer, img_n_label_input_layer, label_input_layer = img_n_label_layer(input_shape, n_classes)\n",
    "\n",
    "    x1 = resNet_block(img_n_label_input_layer, n_filters, 'down')\n",
    "    x2 = resNet_block(x1, 2 * n_filters, 'down')\n",
    "    x3 = resNet_block(x2, 4 * n_filters, 'down')\n",
    "    x4 = resNet_block(x3, 8 * n_filters, 'down')\n",
    "\n",
    "    noise_input_layer = Input(shape=latent_dim)\n",
    "    decoded_img_and_noise = representation_layer(x4, noise_input_layer)\n",
    "\n",
    "    x5 = resNet_block(decoded_img_and_noise, 8 * n_filters, 'up')\n",
    "    skip_connection_3_5 = Concatenate(axis=-1)([x3, x5])\n",
    "    x6 = resNet_block(skip_connection_3_5, 4 * n_filters, 'up')\n",
    "    skip_connection_2_6 = Concatenate(axis=-1)([x2, x6])\n",
    "    x7 = resNet_block(skip_connection_2_6, 2 * n_filters, 'up')\n",
    "    skip_connection_1_7 = Concatenate(axis=-1)([x1, x7])\n",
    "    x8 = resNet_block(skip_connection_1_7, 1, 'up')\n",
    "\n",
    "    gen_output = Activation('tanh')(x8)\n",
    "\n",
    "    model = Model(inputs=[img_input_layer, label_input_layer, noise_input_layer], outputs=gen_output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def define_discriminator(input_shape, n_classes):\n",
    "    img_input_layer, img_n_label_input_layer, label_input_layer = img_n_label_layer(input_shape, n_classes)\n",
    "\n",
    "    model = DenseNet(img_input_layer, img_n_label_input_layer, label_input_layer, reduction=0.5, classes=1)\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=config.lr, beta_1=config.beta_1, beta_2=config.beta_2)\n",
    "    model.compile(optimizer=opt, loss=wasserstein_loss, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "d_optimizer = keras.optimizers.Adam(learning_rate=config.lr, beta_1=config.beta_1, beta_2=config.beta_2)\n",
    "\n",
    "\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    for layer in d_model.layers:\n",
    "        if not isinstance(layer, LayerNormalization):\n",
    "            layer.trainable = False\n",
    "    # d_model.trainable = False\n",
    "    # get img, label and noise inputs from generator model\n",
    "    gen_img, gen_label, gen_noise = g_model.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = g_model.output\n",
    "    # connect image output and label input from generator as inputs to discriminator\n",
    "    gan_output = d_model([gen_output, gen_label])\n",
    "    # define gan model as taking img, noise and label and outputting a classification\n",
    "    model = Model([gen_img, gen_label, gen_noise], gan_output)\n",
    "    # compile model\n",
    "    opt = keras.optimizers.Adam(learning_rate=config.lr, beta_1=config.beta_1, beta_2=config.beta_2)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "    return model"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "Dm0JKqoa5mOz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "ivVF3G7Q5mO0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# example of training an conditional gan on the fashion mnist dataset\n",
    "from matplotlib import pyplot\n",
    "from numpy import ones, mean\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Create net\n",
    "dataset = load_real_data()\n",
    "image_shape = dataset[0][0].shape\n",
    "discriminator = define_discriminator(image_shape, config.dataset_labels)\n",
    "generator = define_generator(config.latent_dim, image_shape, config.dataset_labels)\n",
    "gan = define_gan(generator, discriminator)\n",
    "\n",
    "save_dir = create_save_dir()\n",
    "save_hyperparams(save_dir)\n",
    "\n",
    "#Start training\n",
    "bat_per_epo = int(dataset[0].shape[0] / config.batch_size)\n",
    "half_batch = int(config.batch_size / 2)\n",
    "\n",
    "# lists for keeping track of loss\n",
    "critic_loss_hist, gan_hist, gp_hist = list(), list(), list()\n",
    "# calculate the number of training iterations\n",
    "n_steps = bat_per_epo * config.epochs\n",
    "real_images, real_labels, real_y = [], [], []\n",
    "for i in range(n_steps):\n",
    "    # update the critic more than the generator\n",
    "    critic_loss_tmp, gp_tmp = list(), list()\n",
    "    for _ in range(config.n_critic):\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            real_images, real_labels, real_y = generate_real_samples(half_batch)\n",
    "            real_logits = discriminator([real_images, real_labels])\n",
    "\n",
    "            fake_images, fake_labels, fake_y = generate_fake_samples(generator, config.latent_dim, half_batch)\n",
    "            fake_logits = discriminator([fake_images, fake_labels])\n",
    "\n",
    "            d_cost = wasserstein_loss(real_logits, fake_logits)\n",
    "\n",
    "            gp = gradient_penalty(discriminator, half_batch, real_images, fake_images, real_labels)\n",
    "\n",
    "            d_loss = d_cost + gp * config.grad_weight\n",
    "\n",
    "        critic_loss_tmp.append(d_loss)\n",
    "        gp_tmp.append(gp)\n",
    "\n",
    "        d_gradient = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "        d_optimizer.apply_gradients(zip(d_gradient, discriminator.trainable_variables))\n",
    "\n",
    "    critic_loss_hist.append(critic_loss_tmp)\n",
    "    gp_hist.append(gp_tmp)\n",
    "    # prepare points in latent space as input for the generator\n",
    "    img_input, labels_input, y_gan = real_images, real_labels, real_y\n",
    "    # img_input, labels_input, y_gan = Utils.generate_real_samples(n_batch)\n",
    "    z_input = get_noise(config.latent_dim, half_batch)\n",
    "    # update the generator via the critic's error\n",
    "    g_loss = gan.train_on_batch([img_input, labels_input, z_input], y_gan)\n",
    "    gan_hist.append(g_loss)\n",
    "    # summarize loss on this batch\n",
    "    print('>%d/%d, critic_loss=%.3f, gradient_penalty=%.3f ,gan_loss=%.3f' % (i + 1, n_steps, critic_loss_hist[-1], gp_hist[-1], g_loss))\n",
    "\n",
    "    metrics = {\n",
    "        \"gradient_penalty\": gp_hist[-1],\n",
    "        \"critc_loss\": critic_loss_hist[-1],\n",
    "        \"generator_loss\": g_loss\n",
    "    }\n",
    "\n",
    "    # Log train metrics to wandb\n",
    "    wandb.log(metrics)\n",
    "    # evaluate the model performance every 'epoch'\n",
    "    if (i + 1) % bat_per_epo == 0:\n",
    "        save_models(i, generator, discriminator, save_dir)\n",
    "wandb.finish()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wBPasL-q5mO1",
    "outputId": "2c6cb574-2aee-4910-9eae-46a98228206f"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}